{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691cf4d3",
   "metadata": {},
   "source": [
    "### Author: Rodolfo Elenes\n",
    "\n",
    "Date Created: 8/5/2025\n",
    "\n",
    "Change log:\n",
    "8/5/2025 - Initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8619898",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454df37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import traceback\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe54c619",
   "metadata": {},
   "source": [
    "##### Create gamelog functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266acec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_gamelog_csv(con_memory, player_name, pfr_id):\n",
    "#   Function name: create_player_gamelog_csv\n",
    "#   Description: This function is used to generate a dataframe that contains a player's gamelog\n",
    "#   Parameters: con_memory, player_name, pfr_id\n",
    "#        con_memory(DuckDB object): Connect to DuckDB session\n",
    "#        player_name(str): First and Last name of a player, ex: Saquon Barkley\n",
    "#        pfr_id(str): Pro Football Reference id used in each players URL to retrieve all gamelog information\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The final dataframe that will be exported as a csv file\n",
    "#        status: Tells the parent function this function's run result\n",
    "    \n",
    "    status = \"\"\n",
    "    \n",
    "    # Pickup regular season data\n",
    "    lst_nm_initial = player_name[0].capitalize()  # Get last name initial\n",
    "    time.sleep(6) # to respect website scraping policies\n",
    "    url = f\"https://www.pro-football-reference.com/players/{lst_nm_initial}/{pfr_id}/gamelog/\"\n",
    "    try:\n",
    "        df = build_career_gmlog_df(url)\n",
    "    except Exception as e:\n",
    "        df = pd.DataFrame() # Have to return a value for df for pd.read_html() failures\n",
    "        print(\"\\nError:\", e)\n",
    "        print(f\"Please check: {url}\")\n",
    "        traceback.print_exc()\n",
    "        return df, status\n",
    "            \n",
    "    # Add playoffs data if available\n",
    "    try:\n",
    "        playoffs_df = build_career_gmlog_df(url, playoffs=True)\n",
    "        df = pd.concat([df, playoffs_df])\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        df = df_rebuild(con_memory, df, player_name)\n",
    "        total_rush_att = df['RushAtt'].sum()\n",
    "        if total_rush_att <= 55:   # sets minimum rushing attempt requirement for players to be saved\n",
    "            print(f\"Insufficient gamelog data for {player_name}. Player has {total_rush_att} rushing attempts logged.\")\n",
    "            status = \"Insufficient data\"\n",
    "        else:\n",
    "            print(f\"Gamelog for {player_name}\")\n",
    "            display(df)\n",
    "            status = \"Save\"\n",
    "    except Exception as e:\n",
    "        print(f\"Unsupported gamelog schema for {player_name}. Please check: {url}\")\n",
    "        print(\"\\nError:\", e, \"\\n\")\n",
    "        traceback.print_exc()\n",
    "        return df, status\n",
    "\n",
    "        \n",
    "    return df, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_career_gmlog_df(url, playoffs=False):\n",
    "#   Function name: build_career_gmlog_df\n",
    "#   Description: This function is used to scrape the raw dataframe of the player's gamelog from pfr's website \n",
    "#   Parameters: url, playoffs\n",
    "#        url(str): The URL that points to a player's gamelog\n",
    "#        playoffs(boolean): Tells the function to extract the regular season or playoffs table\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The raw dataframe that will be transformed into the final dataframe\n",
    "    \n",
    "    if playoffs == True:\n",
    "        df = pd.read_html(url, header=[0, 1])[1]\n",
    "    else:\n",
    "        df = pd.read_html(url, header=[0, 1])[0]\n",
    "        \n",
    "    # Fill top-level header missing values forward\n",
    "    cols = pd.DataFrame(df.columns.tolist())\n",
    "    cols.iloc[:, 0] = cols.iloc[:, 0].replace(\"Unnamed:.*\", pd.NA, regex=True).fillna(method='ffill')\n",
    "    # Rebuild MultiIndex\n",
    "    df.columns = pd.MultiIndex.from_frame(cols)\n",
    "    df = df[['NaN', 'Rushing', 'Receiving', 'Snap Counts']]\n",
    "\n",
    "    # Then flatten as before\n",
    "    df.columns = [\n",
    "        f\"{a}_{b}\".strip('_') if b else a \n",
    "        for a, b in df.columns\n",
    "    ]\n",
    "\n",
    "    if playoffs == True:\n",
    "        df['Season_type'] = \"POST\"\n",
    "    else:\n",
    "        df['Season_type'] = \"REG\"\n",
    "        \n",
    "    df = df.loc[:, ~df.columns.duplicated()] # Drops duplicate columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6cd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_rebuild(con_memory, df, player_name):\n",
    "#   Function name: df_rebuild\n",
    "#   Description: This function is used to take the raw dataframe and apply all necessary transformations\n",
    "#   Parameters: con_memory, df\n",
    "#        con_memory(DuckDB object): Connect to DuckDB session\n",
    "#        df(pandas dataframe): The raw input dataframe\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The final dataframe that will be saved as a csv file\n",
    "\n",
    "    # Remove nan_ from Date and GS, rename Gcar col\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        if \"nan\" in col:\n",
    "            if col == 'nan_Gcar':  # Exclusively rename Gcar to CarGm\n",
    "                col = 'CarGm'\n",
    "            new_cols.append(col.replace(\"nan_\", \"\"))\n",
    "        else:\n",
    "            new_cols.append(col)\n",
    "    df.columns = new_cols\n",
    "\n",
    "    # Add columns that are low priority\n",
    "    process_columns = ['CarGm', 'Date', 'GS', 'Season_type', 'Week', 'Team', 'Rushing_Att', 'Rushing_Yds', 'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec', 'Receiving_Yds', 'Receiving_TD', 'Snap Counts_OffSnp', 'Snap Counts_STSnp']\n",
    "    for col in process_columns:\n",
    "        if col not in ['Snap Counts_OffSnp', 'Snap Counts_STSnp']:\n",
    "            continue\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    df = df[process_columns]\n",
    "    \n",
    "    # filter out rows that do not contain games (i.e. header rows, summary rows, etc.)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).reset_index(drop = True)\n",
    "    \n",
    "    # Create Season column\n",
    "    min_year = (df['Date'].min().year) - 1  # subtracting for players who debutted in next calendar year\n",
    "    max_year = df['Date'].max().year\n",
    "    df['Season'] = ''\n",
    "    for i in range(max_year, min_year - 1, -1):\n",
    "        start_date = f\"{i}-08-01\"\n",
    "        end_date = f\"{i + 1}-03-01\"\n",
    "        date_filter = (df['Date'] > start_date) & (df['Date'] <= end_date)\n",
    "        df[\"Season\"] = np.where(date_filter, i, df[\"Season\"])\n",
    "\n",
    "    # Final column rename\n",
    "    edit_df_cols = df.columns.tolist()\n",
    "    final_columns = ['CarGm', 'Date', 'GS', 'Season_type', 'Week', 'Team', 'RushAtt', 'RushYds', 'RushTD', 'Tgt', 'Rec', 'RecYds', 'RecTD', 'OffSnp', 'STSnp', 'Season']\n",
    "    for i in range(df.shape[1]):\n",
    "        edit_df_cols[i] = final_columns[i]\n",
    "    df.columns = edit_df_cols\n",
    "    \n",
    "    df['GS'] = np.where(df['GS'] == '*', 1, 0)  # make Game Started column binary\n",
    "    df = apply_schema(df)\n",
    "        \n",
    "    # Final order\n",
    "    column_order = ['CarGm', 'Date', 'Season', 'Season_type', 'Week', 'Team', 'GS', 'RushAtt', 'RushYds', 'RushTD', 'Tgt', 'Rec', 'RecYds', 'RecTD', 'OffSnp', 'STSnp']\n",
    "    df = df[column_order].sort_values(\"Date\").reset_index(drop=True)\n",
    "    df['CarGm'] = range(1, len(df) + 1) # Numerize the Career Games based off the Dates\n",
    "    df = add_DNP_rows(df, player_name)\n",
    "    df = trnsfrm_bye_weeks(df)\n",
    "    df = add_DNP_dates(con_memory, df)\n",
    "    df = trnsfrm_susp_weeks(df, player_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08166fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_schema(df):\n",
    "#   Function name: apply_schema\n",
    "#   Description: This function is used to apply the correct dataframe schema\n",
    "#   Parameters: df\n",
    "#        input_df(pandas dataframe): The input dataframe\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The transformed dataframe with correct datatypes schema\n",
    "\n",
    "    # apply proper schema\n",
    "    int_cols = ['CarGm', 'Season', 'Week', 'GS', 'RushAtt', 'RushYds', 'RushTD', 'Tgt', 'Rec', 'RecYds', 'RecTD', 'OffSnp', 'STSnp']\n",
    "    for col in int_cols:                \n",
    "        if col not in ['CarGm', 'Season', 'Week', 'GS'] and df[col].isna().any():\n",
    "            df[col] = df[col].fillna(0)\n",
    "        df[col] = df[col].astype(float).astype(int)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea74baf",
   "metadata": {},
   "source": [
    "##### DNP rows transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_DNP_rows(input_df, player_name):\n",
    "#   Function name: add_DNP_rows\n",
    "#   Description: This function is used to add missing DNP rows to the dataframe\n",
    "#   Parameters: input_df, player_name\n",
    "#        input_df(pandas dataframe): The input dataframe\n",
    "#        player_name(str): Name of the player\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The transformed dataframe with DNP rows\n",
    "\n",
    "    con_memory = duckdb.connect(database=':memory:')\n",
    "    career_seasons = input_df['Season'].unique().tolist() # get the seasons in a list\n",
    "\n",
    "    df_gamelog = input_df[(input_df['Season_type'] == 'REG')] # exclude playoffs rows\n",
    "    df_playoffs = input_df[(input_df['Season_type'] == 'POST')] # store playoffs rows\n",
    "    final_columns = input_df.columns\n",
    "    df = pd.DataFrame(columns = final_columns)\n",
    "\n",
    "    # split df_gamelog by seasons\n",
    "    for season in career_seasons:\n",
    "        df_season = df_gamelog[(df_gamelog['Season']) == season]\n",
    "        if season >= 2021:\n",
    "            week_games = list(range(1, 19))\n",
    "        else:\n",
    "            week_games = list(range(1, 18))\n",
    "\n",
    "        df_DNP = pd.DataFrame(columns = final_columns)\n",
    "        games_played = df_season['Week'].tolist()  # get weeks value from season\n",
    "        weeks_missed = list(set(week_games) - set(games_played))  # get games missed\n",
    "\n",
    "        #add DNP rows\n",
    "        for week in weeks_missed:        \n",
    "            df_DNP.loc[-1] = {'Week': week, 'Season_type': 'DNP', 'Season': season}  # Add DNP row\n",
    "            df_DNP = df_DNP.reset_index(drop=True)\n",
    "\n",
    "        df_season = pd.concat([df_season, df_DNP]).sort_values('Week').reset_index(drop=True)\n",
    "        df_season['Team'] = df_season['Team'].ffill()  # fills DNP week with correct team\n",
    "        if df_season['Team'].isna().any(): # in case forward fill doesnt work due to a player beginning the season injured\n",
    "            df_season['Team'] = df_season['Team'].bfill()\n",
    "        df_season = df_season.fillna(0)\n",
    "        df = pd.concat([df, df_season])\n",
    "\n",
    "    df = pd.concat([df, df_playoffs])\n",
    "    df = df.sort_values(by = ['Season', 'Week']).reset_index(drop=True)\n",
    "    \n",
    "    # Add missing seasons\n",
    "    df_sched = pd.read_csv(f\"../tables/nfl_team_schedules/nfl_team_schedules.csv\")\n",
    "    df_roster = construct_df_roster(con_memory)\n",
    "    df_roster = df_roster[(df_roster.Player == player_name) & (df_roster.ABV.isin(df.Team.unique().tolist()))]\n",
    "\n",
    "    gamelog_szns = df.Season.unique().tolist()\n",
    "    roster_szns = df_roster.Season.unique().tolist()\n",
    "\n",
    "    if gamelog_szns != roster_szns:\n",
    "        missing_szns_chk = all(b - a == 1 for a, b in zip(gamelog_szns, gamelog_szns[1:]))\n",
    "    else:\n",
    "        missing_szns_chk = True\n",
    "\n",
    "    if missing_szns_chk == False:\n",
    "        missing_szns = list(set(roster_szns) - set(gamelog_szns))\n",
    "        for year in missing_szns:\n",
    "            if year >= 2021:\n",
    "                week_games = list(range(1, 19))\n",
    "            else:\n",
    "                week_games = list(range(1, 18))\n",
    "\n",
    "            df_temp = df[(df.Season == (year - 1))].reset_index(drop=True)\n",
    "            df_temp2 = df_roster[(df_roster.Season == year)].reset_index(drop=True)\n",
    "\n",
    "            df_mss_sched = df_sched[(df_sched.Team == df_temp2.iloc[0].loc['Team']) & (df_sched.Season == year)]   \n",
    "            df_temp.loc[-1] = {'CarGm': 0, 'Date': df_mss_sched.Date.tolist(), 'Season': year, 'Season_type': 'DNP', 'Team': df_temp2.iloc[0].loc['team'], 'Week': df_mss_sched.Week.tolist()}\n",
    "            df_temp = df_temp.explode(['Date', 'Week'])\n",
    "            df_temp = df_temp[(df_temp.Season == year) & (df_temp.Week.isin(week_games))].fillna(0)\n",
    "            df = pd.concat([df, df_temp]).sort_values(by=['Season', 'Week']).reset_index(drop=True)\n",
    "    \n",
    "    df = apply_schema(df)\n",
    "    con_memory.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trnsfrm_bye_weeks(df):\n",
    "#   Function name: find_bye_weeks\n",
    "#   Description: This function is used to correctly identify the bye weeks on DNP rows\n",
    "#   Parameters: df\n",
    "#        df(pandas dataframe): The input dataframe\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The transformed dataframe with BYE week rows\n",
    "\n",
    "    df_fltrd = df[(df[\"Season_type\"] == 'DNP')]\n",
    "    teams_played_for = df_fltrd['Team'].unique().tolist()\n",
    "    years_played_for = df_fltrd['Season'].unique().tolist()\n",
    "\n",
    "    df_teams = construct_df_teams()\n",
    "\n",
    "    # Get all the bye weeks relevant to the player\n",
    "    df_bye = pd.read_csv(\"../tables/bye_weeks_xref/bye_weeks_xref.csv\")\n",
    "    df_bye = pd.merge(df_bye, df_teams, on=['Team', 'PFR_ABV'], how='inner')\n",
    "    df_bye = df_bye[df_bye.ABV.isin(teams_played_for)].reset_index(drop=True)\n",
    "    df_bye = df_bye[df_bye.Season.isin(years_played_for)].reset_index(drop=True)\n",
    "    df_bye = df_bye[['ABV', 'Season', 'Bye Week']]\n",
    "    \n",
    "    # Match the correct bye week to the players log on DNP rows\n",
    "    merged_df = pd.merge(df_fltrd, df_bye, left_on=['Team', 'Season'], right_on=['ABV', 'Season'], how='inner')\n",
    "    merged_df = merged_df[(merged_df[\"Week\"] == merged_df[\"Bye Week\"])]\n",
    "    merged_df['Season_type'] = \"BYE\"\n",
    "    merged_df = merged_df[df.columns].reset_index(drop=True)\n",
    "\n",
    "    # Apply BYE week rows to the final df\n",
    "    for row in range(merged_df.shape[0]):\n",
    "        week_entry = merged_df.loc[row]\n",
    "        season = week_entry.loc['Season']\n",
    "        week = week_entry.loc['Week']\n",
    "        index_row = df[(df['Season'] == season) & (df['Week'] == week)].index[0]\n",
    "        df.loc[index_row] = week_entry\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_DNP_dates(con_memory, df):\n",
    "#   Function name: add_DNP_dates\n",
    "#   Description: Fill in correct dates for DNP rows\n",
    "#   Parameters: con_memory, df\n",
    "#        con_memory(DuckDB object): Connect to DuckDB session\n",
    "#        df(pandas dataframe): The input dataframe\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The transformed dataframe with filled out dates column\n",
    "\n",
    "    df_sched = pd.read_csv(\"../tables/nfl_team_schedules/nfl_team_schedules.csv\")\n",
    "    df_DNP = df[(df[\"Season_type\"] == 'DNP')]\n",
    "    df_teams = construct_df_teams()\n",
    "\n",
    "    df_sched = con_memory.execute(f\"\"\"SELECT df_sched.*, df_teams.ABV FROM df_sched \n",
    "                                 JOIN df_teams ON df_sched.Team = df_teams.Team\"\"\").fetchdf()\n",
    "\n",
    "    df_DNP = con_memory.execute(f\"\"\"SELECT df_DNP.*, df_teams.Team as Team_Name FROM df_DNP \n",
    "                                 JOIN df_teams ON df_DNP.Team = df_teams.ABV\"\"\").fetchdf()\n",
    "\n",
    "    df_DNP = con_memory.execute(f\"\"\" SELECT CarGm, df_sched.Date, df_DNP.* EXCLUDE (Team_Name, Date, CarGm)\n",
    "                                 FROM df_sched JOIN df_DNP \n",
    "                                 ON df_sched.Team = df_DNP.Team_Name \n",
    "                                 AND df_sched.Season = df_DNP.Season AND df_sched.Week = df_DNP.Week \n",
    "                                 ORDER BY df_sched.Date\"\"\").fetchdf()\n",
    "    \n",
    "    df = df[(df['Season_type'] != 'DNP')]\n",
    "    df = pd.concat([df, df_DNP]).sort_values(by=['Season', 'Week']).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trnsfrm_susp_weeks(df, player_name):\n",
    "#   Function name: trnsfrm_susp_weeks\n",
    "#   Description: Transform DNP weeks into SUSP (suspended) rows based off the susp_weeks_xref.csv table\n",
    "#   Parameters: df, player_name\n",
    "#        df(pandas dataframe): The input dataframe\n",
    "#        player_name(str): Name of the player\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The transformed dataframe with target DNP rows transformed to SUSP\n",
    "\n",
    "    szns_plyd = df.Season.unique().tolist()\n",
    "    df_teams = construct_df_teams()\n",
    "    df_susp = pd.read_csv(\"../tables/susp_weeks_xref.csv\")\n",
    "    df_susp = df_susp[(df_susp.Player == player_name) & (df_susp.Season.isin(szns_plyd))].reset_index(drop=True)\n",
    "\n",
    "    for row in range(df_susp.shape[0]):\n",
    "        susp_entry = df_susp.loc[row]\n",
    "        if \"game\" in susp_entry.loc['Susp_len'].lower():      # For entries of x games suspensions\n",
    "            susp_entry['Susp_len'] = int(susp_entry.Susp_len.split(\" \")[0])\n",
    "            susp_date = susp_entry.loc['Date']\n",
    "            susp_len = susp_entry.loc['Susp_len']\n",
    "            df_susp_dates = df[(df.Date >= susp_date) & (df[\"Season_type\"] == 'DNP')]\n",
    "            df_susp_dates = df_susp_dates.head(susp_len)\n",
    "            df_susp_dates['Season_type'] = 'SUSP'\n",
    "            idx_list = df_susp_dates.index.tolist()\n",
    "            df.loc[idx_list] = df_susp_dates.loc[idx_list]\n",
    "        else:                                                 # For entries of Entire xxxx Season suspensions\n",
    "            susp_date = susp_entry.loc['Date']\n",
    "            susp_szn = susp_entry.loc['Season']\n",
    "            df_susp_dates = df[(df.Date >= susp_date) & (df[\"Season_type\"] == 'DNP') & (df[\"Season\"] == susp_szn)]\n",
    "            df_susp_dates['Season_type'] = 'SUSP'\n",
    "            idx_list = df_susp_dates.index.tolist()\n",
    "            df.loc[idx_list] = df_susp_dates.loc[idx_list]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8b48a",
   "metadata": {},
   "source": [
    "###### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c085f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "#   Function name: main\n",
    "#   Description: The entry function of the notebook\n",
    "\n",
    "    con_memory = duckdb.connect(database=':memory:')\n",
    "    print(\"All players that will have gamelog data scraped.\")\n",
    "    players_xref_path = \"../tables/players_xref.csv\"\n",
    "    player_db = pd.read_csv(players_xref_path)\n",
    "    fltrd_player_db = player_db[player_db['gm_log_rtrvd'] == 0].reset_index(drop = True)\n",
    "    player_count = 1\n",
    "    display(fltrd_player_db)\n",
    "    \n",
    "    for row in range(player_db.shape[0]):\n",
    "        player_entry = player_db.loc[row]\n",
    "        player_name = player_entry.loc['full_name']\n",
    "        pfr_id = player_entry.loc['pfr_id']\n",
    "        gm_log_rtrvd = player_entry.loc['gm_log_rtrvd']\n",
    "        \n",
    "        if gm_log_rtrvd == 0:\n",
    "            print(f\"Player ({player_count}/{fltrd_player_db.shape[0]}): {player_name}\")\n",
    "            df, status = create_player_gamelog_csv(con_memory, player_name, pfr_id)\n",
    "            \n",
    "            if status == \"Save\":\n",
    "                gm_log_entry = 1 # Successful save\n",
    "                save_df(df, \"../tables/players_gamelogs/players\", f\"{player_name}_gamelog.csv\")\n",
    "            elif status == \"Insufficient data\":\n",
    "                gm_log_entry = 2 # Insufficient data\n",
    "            else:\n",
    "                gm_log_entry = 3 # Failed save (lets me know to debug)\n",
    "            \n",
    "            player_db.loc[row, 'gm_log_rtrvd'] = gm_log_entry\n",
    "            player_db.to_csv(players_xref_path, index = False)\n",
    "            print(f\"Updated gm_log_rtrvd entry to {gm_log_entry} in players_ref.csv for {player_name}\")\n",
    "            player_count = player_count + 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    print(f\"Completed acquiring gamelog for {fltrd_player_db.shape[0]} players.\")\n",
    "    con_memory.close()\n",
    "    \n",
    "    if fltrd_player_db.shape[0] > 0:\n",
    "        concatenate_all_files('players_gamelogs', 'players')\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758fad9",
   "metadata": {},
   "source": [
    "# Side Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1110a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_memory = duckdb.connect(database=':memory:')\n",
    "df_susp = pd.read_csv(\"../tables/susp_weeks_xref.csv\")\n",
    "df_roster = construct_df_roster(con_memory)\n",
    "# display(df_susp)\n",
    "# display(df_roster)\n",
    "\n",
    "df_susp = con_memory.execute(\"\"\"SELECT * FROM df_susp JOIN df_roster\n",
    "                                ON df_susp.Player = df_roster.name\n",
    "                                \"\"\").fetchdf()\n",
    "display(df_susp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ac456c",
   "metadata": {},
   "source": [
    "Prototype code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf8d01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # adding missing seasons in add_DNP_rows()\n",
    "\n",
    "# player = 'Roosevelt Potts'\n",
    "# df = pd.read_csv(f\"../tables/players_gamelog/{player}_gamelog.csv\")\n",
    "# df_sched = pd.read_csv(f\"../tables/nfl_team_schedules.csv\")\n",
    "# df_teams = construct_df_teams()\n",
    "# df_roster = construct_df_roster(duckdb.connect(database=':memory:'))\n",
    "# df_roster = pd.merge(df_roster, df_teams, left_on = 'team', right_on = 'ABV')\n",
    "# df_roster = df_roster[(df_roster.name == player) & (df_roster.team.isin(df.Team.unique().tolist()))]\n",
    "\n",
    "# gamelog_szns = df.Season.unique().tolist()\n",
    "# roster_szns = df_roster.season.unique().tolist()\n",
    "\n",
    "# if gamelog_szns != roster_szns:\n",
    "#     missing_szns_chk = all(b - a == 1 for a, b in zip(gamelog_szns, gamelog_szns[1:]))\n",
    "# else:\n",
    "#     missing_szns_chk = True\n",
    "\n",
    "# if missing_szns_chk == False:\n",
    "#     missing_szns = list(set(roster_szns) - set(gamelog_szns))\n",
    "#     for year in missing_szns:\n",
    "#         if year >= 2021:\n",
    "#             week_games = list(range(1, 19))\n",
    "#         else:\n",
    "#             week_games = list(range(1, 18))\n",
    "        \n",
    "#         df_temp = df[(df.Season == (year - 1))].reset_index(drop=True)\n",
    "#         df_temp2 = df_roster[(df_roster.season == year)].reset_index(drop=True)\n",
    "        \n",
    "#         df_mss_sched = df_sched[(df_sched.Team == df_temp2.iloc[0].loc['Team']) & (df_sched.Season == year)]   \n",
    "#         df_temp.loc[-1] = {'CarGm': 0, 'Date': df_mss_sched.Date.tolist(), 'Season': year, 'Season_type': 'DNP', 'Team': df_temp2.iloc[0].loc['team'], 'Week': df_mss_sched.Week.tolist()}\n",
    "#         df_temp = df_temp.explode(['Date', 'Week'])\n",
    "#         df_temp = df_temp[(df_temp.Season == year) & (df_temp.Week.isin(week_games))].fillna(0)\n",
    "#         df = pd.concat([df, df_temp]).sort_values(by=['Season', 'Week']).reset_index(drop=True)\n",
    "# else:\n",
    "#     print('No missing seasons')\n",
    "    \n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3acbab",
   "metadata": {},
   "source": [
    "##### Injury data exploration (comeback later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c88321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nfl_data_py as nfl\n",
    "# injuries_df = nfl.import_injuries(list(range(2009, 2025))) # Specify the years you want to retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf82116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Actual Injuries that I will count\n",
    "# query = injuries_df[(injuries_df['position'] == 'RB') & (injuries_df['full_name'] == 'Kyren Williams')\n",
    "#                     & (~injuries_df['report_primary_injury'].str.contains(\"Coach|Decision|Not Injury|Non Injury|COVID|Personal|Non-Football Illness|Non Football Illness|non football injury\", case=False, na=False))].dropna(subset=['report_status'])\n",
    "# query = query[['season', 'game_type', 'team', 'week', 'full_name', 'report_primary_injury', 'report_secondary_injury', 'report_status']]\n",
    "# for i in ['season', 'week']:\n",
    "#     query[i] = query[i].astype(int)\n",
    "# display(query)\n",
    "\n",
    "# ##############################################################################################################################################################################\n",
    "\n",
    "# display(pd.read_csv(\"../tables/players_gamelog/Kyren Williams_gamelog.csv\").query(\"Season_type == 'DNP'\"))\n",
    "\n",
    "# ##############################################################################################################################################################################\n",
    "\n",
    "# # Non injuries leaves (will stay as DNP, but will be logged)\n",
    "# query = injuries_df[(injuries_df['position'] == 'RB') & (injuries_df['full_name'] == 'Kyren Williams')\n",
    "#                     & (injuries_df['report_primary_injury'].str.contains(\"Coach|Decision|Not Injury|Non Injury|COVID|Personal|Non-Football Illness|Non Football Illness|non football injury\", case=False))].dropna(subset=['report_status'])\n",
    "# query = query[['season', 'game_type', 'team', 'week', 'full_name', 'report_primary_injury', 'report_secondary_injury', 'report_status']]\n",
    "# for i in ['season', 'week']:\n",
    "#     query[i] = query[i].astype(int)\n",
    "# display(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea72178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make function that checks consecutive DNP rows, and flags when player has big injury\n",
    "\n",
    "# lst = [4, 5, 6, 9, 10, 11, 13, 14]\n",
    "# lst.sort(reverse=True)\n",
    "# print(lst)\n",
    "\n",
    "# injury_list = []\n",
    "# sub_list = []\n",
    "# big_injury = False\n",
    "# for i in lst:\n",
    "#     if sub_list == []:\n",
    "#         sub_list.append(i)\n",
    "#         continue\n",
    "#     prev_num = sub_list.pop()\n",
    "#     subtract = prev_num - i\n",
    "#     print(subtract)\n",
    "#     sub_list.append(i)\n",
    "#     if subtract == 1:\n",
    "#         injury_list.append(subtract)\n",
    "#     else:\n",
    "#         injury_list.clear()\n",
    "\n",
    "#     if len(injury_list) >= 3:\n",
    "#         big_injury = True        \n",
    "        \n",
    "# if big_injury == True:\n",
    "#     print('player had big injury this year')\n",
    "# else:\n",
    "#     print('player had no big injuries')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFL",
   "language": "python",
   "name": "nfl_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
