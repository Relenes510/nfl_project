{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d323ab",
   "metadata": {},
   "source": [
    "### Author: Rodolfo Elenes\n",
    "\n",
    "Date Created: 8/12/2025\n",
    "\n",
    "Change log:\n",
    "8/12/2025 - Initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5a984",
   "metadata": {},
   "source": [
    "# Notebook to do list\n",
    "    1.) 1993 was the ONLY 2 bye week system year, ensure this is processed correctly\n",
    "    2.) 1999 Chargers, 2000 Bengals, and 2001 Cardinals the only week 1 bye week teams\n",
    "            -and tampa + miami in 2017\n",
    "    3.) The 1999 & 2000 Browns had a bye week in week 17\n",
    "    \n",
    "# Enhancements\n",
    "        1.) Add data validation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9aeb6f",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8ead45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026f20c",
   "metadata": {},
   "source": [
    "##### Notebook functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a34dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_bye_weeks(team_name, pfr_abv, seasons):\n",
    "#   Function name: get_team_bye_weeks\n",
    "#   Description: Generates a dataframe with all of the team's bye weeks since 1990\n",
    "#   Parameters: team_name, pfr_abv, seasons\n",
    "#        team_name(str): The team's official name\n",
    "#        pfr_abv(str): The abbreviation used by Pro Football Reference in their URL\n",
    "#        seasons(list): All of the seasons since 1990\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The dataframe with the team's data on all of its bye weeks since 1990\n",
    "\n",
    "    bye_week_list = []\n",
    "    df_seasons_list = [] # Helps process 1993s 2 bye week year + possible pd.read_html errors\n",
    "        \n",
    "    # Go through every season \n",
    "    for year in seasons:\n",
    "        url = f\"https://www.pro-football-reference.com/teams/{pfr_abv}/{year}.htm\"\n",
    "        try:\n",
    "            df_schedule = pd.read_html(url, header=[0, 1])[1]\n",
    "        except Exception as e:\n",
    "            print(f\"Unavailable link. Please check: {url}\")\n",
    "            print(\"\\nError:\", e, \"\\n\")\n",
    "            continue\n",
    "\n",
    "        # Flatten out multiindex dataframe from pd.read_html\n",
    "        cols = pd.DataFrame(df_schedule.columns.tolist())\n",
    "        cols.iloc[:, 0] = cols.iloc[:, 0].replace(\"Unnamed:.*\", pd.NA, regex=True).fillna(method='ffill')\n",
    "        df_schedule.columns = pd.MultiIndex.from_frame(cols)\n",
    "        df_schedule.columns = [\n",
    "            f\"{a}_{b}\".strip('_') if b else a \n",
    "            for a, b in df_schedule.columns\n",
    "        ]\n",
    "\n",
    "        # Setup dictionary contents that will be fed into final dataframe\n",
    "        df_schedule = df_schedule[['nan_Week', 'nan_Opp']]        \n",
    "        check_df_sched = df_schedule[(df_schedule['nan_Opp'] == 'Bye Week')]\n",
    "        if check_df_sched.shape[0] == 0:\n",
    "            check_df_sched = get_missing_bye(df_schedule, year)\n",
    "            print(f\"Successfully added the missing bye week to the {team_name} {year} season.\")\n",
    "        for i in range(check_df_sched.shape[0]): # Helps 1993s 2 bye week season\n",
    "            bye_week = check_df_sched.iloc[i]['nan_Week']\n",
    "            bye_week_list.append(bye_week)\n",
    "            df_seasons_list.append(year)\n",
    "        print(f\"Acquired {year} season.\")\n",
    "        time.sleep(6) \n",
    "        \n",
    "    # Create final dataframe from dictionary\n",
    "    bye_week_dict = {\"Season\": df_seasons_list, \"Bye Week\": bye_week_list}\n",
    "    df = pd.DataFrame(columns = ['Season', 'Bye Week'], data = bye_week_dict)\n",
    "    df['Team'] = team_name\n",
    "    df = df[['Team', 'Season', 'Bye Week']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1de2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_bye(df, year):\n",
    "#   Function name: get_missing_bye\n",
    "#   Description: Calculates missing bye week for special cases (2001 Arizona Cardinals Week 1)\n",
    "#   Parameters: df, year\n",
    "#        df(pandas dataframe): The dataframe that contains a missing week of data\n",
    "#        year(str): The year of the NFL season\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The corrected dataframe with the new row of data\n",
    "\n",
    "    if year >= 2021:\n",
    "        week_games = list(range(1, 19))\n",
    "    else:\n",
    "        week_games = list(range(1, 18))\n",
    "    games_played = df['nan_Week'].tolist()  # get weeks value from season\n",
    "    missing_week = list(set(week_games) - set(games_played))  # get games missed\n",
    "    df.loc[-1] = {'nan_Week': missing_week[0], 'nan_Opp': 'Bye Week'}  # Add bye week row\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df[(df['nan_Opp'] == 'Bye Week')]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f410f45",
   "metadata": {},
   "source": [
    "##### Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03858df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, save_location, csv_name):\n",
    "#   Function name: save_df\n",
    "#   Description: This function is used to save any dataframe as a csv\n",
    "#   Parameters: df, save_location, csv_name\n",
    "#        df(pandas dataframe): The target dataframe\n",
    "#        save_location(str): Specified location for the csv file to be saved\n",
    "#        csv_name(str): Name of the csv file\n",
    "    \n",
    "    # creates folder if not existence\n",
    "    output_dir = Path(save_location)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    save_loctn = f\"{save_location}/{csv_name}\"\n",
    "    print(f\"Saving {csv_name} at {save_loctn}\")\n",
    "    df.to_csv(save_loctn, index = False)\n",
    "    print(f\"Successfully saved {csv_name}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8842ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exempt_list():\n",
    "#   Function name: get_missing_bye\n",
    "#   Description: Checks for existing bye_week.csv files, so they arent reprocessed again\n",
    "#   Return values: exempt_list\n",
    "#        exempt_list(list): The list of teams that have already been processed by this notebook\n",
    "\n",
    "    save_location = \"../tables/bye_weeks_xref/teams\"\n",
    "\n",
    "    # creates folder if not existence\n",
    "    output_dir = Path(save_location)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    directory_path = Path(save_location)  # Replace with your directory path\n",
    "    file_paths = [entry for entry in directory_path.iterdir() if entry.is_file()]\n",
    "    file_names = [file.name for file in file_paths]\n",
    "\n",
    "    exempt_list = []\n",
    "    for i in file_names:\n",
    "        exempt_list.append(i.split(\"_\")[0])\n",
    "        \n",
    "    return exempt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a61819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_all_files():\n",
    "#   Function name: concatenate_all_files\n",
    "#   Description: This function is used to save the final dataframe as a csv file by collecting all individual team csv files\n",
    "\n",
    "    folder_location = \"../tables/bye_weeks_xref\"\n",
    "    directory_path = Path(folder_location + \"/teams\")  # Replace with your directory path\n",
    "    file_paths = [entry for entry in directory_path.iterdir() if entry.is_file()]\n",
    "    file_names = [file.name for file in file_paths]\n",
    "\n",
    "    df = pd.DataFrame(columns = ['Team', 'Season', 'Bye Week']) # Final Dataframe\n",
    "    \n",
    "    for file in file_names:\n",
    "        df_temp = pd.read_csv(folder_location + \"/teams/\" + file)\n",
    "        df = pd.concat([df, df_temp])\n",
    "        \n",
    "    display(df)\n",
    "    save_df(df, folder_location, 'bye_weeks_xref.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922c96f",
   "metadata": {},
   "source": [
    "##### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c9e1a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will acquire bye weeks data for the following teams: []\n",
      "Files are up to date!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "#   Function name: main\n",
    "#   Description: The entry function of the notebook\n",
    "\n",
    "    teams_df = pd.read_csv(\"../tables/team_info_xref.csv\")\n",
    "    teams_df = teams_df[['Team', 'PFR_ABV']]\n",
    "    exempt_list = create_exempt_list()\n",
    "    teams_df = teams_df[~teams_df.Team.isin(exempt_list)].reset_index(drop=True)\n",
    "    print(f\"Will acquire bye weeks data for the following teams: {teams_df.Team.tolist()}\")\n",
    "    \n",
    "    for row in range(teams_df.shape[0]):\n",
    "        seasons = list(range(1990, datetime.now().year)) # 1990 was the year the NFL introduced bye weeks\n",
    "        team_entry = teams_df.loc[row]\n",
    "        team_name = team_entry.loc['Team']\n",
    "        pfr_abv = team_entry.loc['PFR_ABV']\n",
    "        print(f\"Getting the bye weeks for the {team_name}\")\n",
    "        df_temp = get_team_bye_weeks(team_name, pfr_abv, seasons)\n",
    "        print(f\"Final dataframe for {team_name}:\")\n",
    "        display(df_temp)\n",
    "        save_df(df_temp, '../tables/bye_weeks_xref/teams', f'{team_name}_bye_weeks.csv')\n",
    "    if teams_df.shape[0] > 0:\n",
    "        concatenate_all_files()\n",
    "    else:\n",
    "        print(\"Files are up to date!\")\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad60859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurobi",
   "language": "python",
   "name": "gurobi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
