{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d323ab",
   "metadata": {},
   "source": [
    "### Author: Rodolfo Elenes\n",
    "\n",
    "Date Created: 8/14/2025\n",
    "\n",
    "Change log:\n",
    "8/14/2025 - Initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9aeb6f",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8ead45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import duckdb\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f972d8",
   "metadata": {},
   "source": [
    "##### Notebook Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2623bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_wiki_tbl(con_memory):\n",
    "#   Function name: construct_wiki_tbl\n",
    "#   Description: Create the base of the Wikipedia table\n",
    "#   Parameters: con_memory\n",
    "#        con_memory(ducbdb object): used to carry duckdb queries\n",
    "#   Return values: wiki\n",
    "#        wiki(pandas dataframe): The dataframe with all suspension data from Wikipedia\n",
    "\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_suspensions_in_the_NFL\"\n",
    "    print(\"Attempting to construct Wikipedia table from:\", url)\n",
    "    # Scrape data from Wikipedia\n",
    "    columns = [\"Date suspended\", \"Suspension length\", \"Name\", \"Position\", \"Team at the time of suspension\"]\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    for i in [0, 1]: # Gather Player suspensions + Suspensions for violating the substance policies\n",
    "        time.sleep(6) # Respect website scraping policies\n",
    "        df_temp = scrape_web_src(url, i)\n",
    "        df_temp = df_temp[columns]\n",
    "        df = pd.concat([df, df_temp])\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date suspended'], format=\"%B %d, %Y\", errors='coerce')\n",
    "    df['Date'] = np.where(df.Date.isnull(), pd.to_datetime(df['Date suspended'], format=\"%B %Y\", errors='coerce'), df.Date)\n",
    "\n",
    "    # Column renaming\n",
    "    edit_df_cols = df.columns.tolist()\n",
    "    final_columns = ['Date', 'Susp_len', 'Player', 'Position', 'Team', 'Drop']\n",
    "    for i in range(df.shape[1]):\n",
    "        edit_df_cols[i] = final_columns[i]\n",
    "    df.columns = edit_df_cols\n",
    "\n",
    "    # Final transformations\n",
    "    df['Date'] = df['Drop']\n",
    "    df = df.drop('Drop', axis=1)\n",
    "    df['Position'] = np.where(df['Position'].isin(['FB', 'HB']), 'RB', df.Position) # THINK ABOUT: u want to convert positions to RB\n",
    "    df = df[(df['Date'] >= '1990') & (df['Position'] == 'RB') & (~df.Susp_len.str.contains('overturned', case=False))]\n",
    "\n",
    "    # Hard code fixes\n",
    "    df['Susp_len'] = np.where(df.Susp_len == 'Indefinite (reinstated in Feb. 2015)[116]', 'Entire 2014 season', df.Susp_len)\n",
    "    df['Susp_len'] = np.where(df.Susp_len == 'Indefinite[d] (reinstated four days later)[133]', '1 games', df.Susp_len)\n",
    "    df['Susp_len'] = np.where(df.Susp_len == 'Indefinite (reinstated in Aug. 2012)[311]', 'Indefinite', df.Susp_len)\n",
    "    df['Susp_len'] = np.where(df.Susp_len == 'Indefinite (reinstated in Dec. 2016)[532]', 'Entire 2016 season', df.Susp_len)\n",
    "    df['Susp_len'] = np.where(df.Susp_len == 'Indefinite', \"Entire \" + df['Date'].dt.year.astype(str) + \" season\", df.Susp_len)\n",
    "    df['Susp_len'] = np.where(df.Susp_len == '3 games (later reduced to 2 games)[476]', '2 games', df.Susp_len)\n",
    "\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Get rows with \"Entire\" in Susp_len\n",
    "    df2 = df.query(\"Susp_len.str.contains('entire', case=False)\")\n",
    "    susp_list1 = df2.Susp_len.unique().tolist()\n",
    "\n",
    "    # Get rows with only number of game suspensions defined\n",
    "    df3 = df[(~df['Susp_len'].isin(susp_list1))]\n",
    "    susp_list2 = df3.Susp_len.tolist()\n",
    "    fltrd_susp_list2 = []\n",
    "    for i in susp_list2: # Remove inconsistent games/games[d] phrasing\n",
    "        fltrd_susp_list2.append(i.split(\" \")[0])    \n",
    "    df3['Susp_len'] = fltrd_susp_list2\n",
    "    df3['Susp_len'] = df3.Susp_len + \" games\" # Added back games for consistency\n",
    "\n",
    "    wiki = pd.concat([df2, df3])\n",
    "    \n",
    "    # Attach Season and Week information to the suspended players\n",
    "    df_dates = pd.read_csv(\"../tables/nfl_dates_xref.csv\")\n",
    "    wiki = con_memory.execute(\"SELECT * FROM wiki JOIN df_dates ON df_dates.Date = wiki.Date\").fetchdf()\n",
    "    wiki['Date'] = pd.to_datetime(wiki.Date, format='%Y-%m-%d')\n",
    "    print(\"Wikipedia table constructed.\")\n",
    "    \n",
    "    return wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785086fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_pst_tbl(con_memory):\n",
    "#   Function name: construct_pst_tbl\n",
    "#   Description: Create the base of the PST table\n",
    "#   Parameters: con_memory\n",
    "#        con_memory(ducbdb object): used to carry duckdb queries\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The dataframe with all suspension data from prosportstransactions.com\n",
    "\n",
    "    src_tbl = \"../src/nfl_suspensions_by_pst.csv\"\n",
    "    print(\"Attempting to construct Prosportstransactions.com table from:\", src_tbl)\n",
    "    df_roster = construct_roster_df(con_memory)\n",
    "\n",
    "    # Construct df_teams by flattening team_info_xref.csv\n",
    "    df_teams = pd.read_csv(\"../tables/team_info_xref.csv\")\n",
    "    df_ABV = df_teams.dropna(subset=['ABV2']).reset_index(drop=True)\n",
    "    row_loc = -1 # the pointer for the last row of the dataframe\n",
    "    for row in range(df_ABV.shape[0]):\n",
    "        team_entry = df_ABV.loc[row]\n",
    "        pfr_abv = team_entry.loc['PFR_ABV']\n",
    "        team_name = team_entry.loc['Team']\n",
    "        team_name2 = team_entry.loc['Team2']\n",
    "        team_name3 = team_entry.loc['Team3']\n",
    "        ABV2 = team_entry.loc['ABV2']\n",
    "        ABV3 = team_entry.loc['ABV3']\n",
    "        df_teams.loc[row_loc] = {'Team': team_name2, 'ABV': ABV2, 'PFR_ABV': pfr_abv}\n",
    "        row_loc = row_loc - 1\n",
    "        if str(ABV3) != 'nan':\n",
    "            df_teams.loc[row_loc] = {'Team': team_name3, 'ABV': ABV3, 'PFR_ABV': pfr_abv}\n",
    "            row_loc = row_loc - 1\n",
    "    df_teams = df_teams[['Team', 'ABV', 'PFR_ABV']].sort_values('PFR_ABV').reset_index(drop=True)\n",
    "    df_teams['short_name'] = df_teams.Team.str.split(\" \").str[-1]\n",
    "\n",
    "    # Join df_teams with df_roster to have a records of all players and the correct team identifiers\n",
    "    df = con_memory.execute(\"\"\"SELECT season, Team, short_name, ABV, PFR_ABV, name as Player, position AS Position FROM\n",
    "                                   (SELECT * FROM df_teams JOIN df_roster ON df_teams.ABV = df_roster.team)\"\"\").fetchdf()\n",
    "    drop_target = df[(df.Team == 'Houston Oilers') & (df.PFR_ABV == 'oti') & (df.season >= 1997)].index # filter out innaccurate HOU Oilers rows\n",
    "    df = df.drop(drop_target)\n",
    "    drop_target = df[(df.Team == 'Houston Texans') & (df.PFR_ABV == 'htx') & (df.season <= 2001)].index # filter out innaccurate HOU Texans rows\n",
    "    df = df.drop(drop_target)\n",
    "    df = df.drop('season', axis=1).drop_duplicates()\n",
    "    con_memory.register('roster', df)\n",
    "    \n",
    "    # Construct suspensions data from Prosportstransactions.com and join with rosters table to bring identifiers to suspended players\n",
    "    df = pd.read_csv(src_tbl)\n",
    "    df = df[['Date', 'Team', 'Acquired', 'Relinquished', 'Notes']]\n",
    "    df['Acquired'] = np.where(df.Acquired == '#VALUE!', np.nan, df.Acquired)\n",
    "    df['Relinquished'] = np.where(df.Relinquished == '#VALUE!', np.nan, df.Relinquished)\n",
    "    df['Team'] = np.where(df.Team.isnull(), 'Free Agent', df.Team)\n",
    "    df['Date'] = pd.to_datetime(df.Date)\n",
    "    df['name'] = np.where(df.Acquired.isnull() == False, df.Acquired, np.nan)\n",
    "    df['name'] = np.where(df.Relinquished.isnull() == False, df.Relinquished, np.nan)\n",
    "    df = con_memory.execute(\"SELECT * FROM roster JOIN df ON roster.Player = df.name AND roster.short_name = df.Team\").fetchdf()\n",
    "    con_memory.register('pst', df)\n",
    "\n",
    "    # Attach Season and Week information to the suspended players and filter out fines entries\n",
    "    df_dates = pd.read_csv(\"../tables/nfl_dates_xref.csv\")\n",
    "    df = con_memory.execute(\"\"\"SELECT Season, Week, Date, Team, Player, Notes AS Susp_len FROM \n",
    "                               (SELECT * FROM df_dates JOIN pst ON df_dates.Date = pst.Date) \n",
    "                               WHERE Notes NOT ILIKE '%fine%' \n",
    "                               ORDER BY Date\"\"\").fetchdf()\n",
    "\n",
    "    # Extract suspension lengths\n",
    "    filter_list = df.Susp_len.unique()\n",
    "    pattern = r\"\\b\\d+\\s+games?\\b\"\n",
    "    matches = []\n",
    "    for text in filter_list:\n",
    "        found = re.findall(pattern, text.lower())\n",
    "        if found:\n",
    "            matches.extend(found)\n",
    "            df['Susp_len'] = np.where(df.Susp_len == text, found[0], df.Susp_len)\n",
    "    df['Date'] = pd.to_datetime(df.Date, format='%Y-%m-%d')\n",
    "    df['Susp_len'] = np.where(df['Susp_len'].str.contains('indef'), \"Entire \" + df['Date'].dt.year.astype(str) + \" season\", df.Susp_len)\n",
    "    df = df[(df['Susp_len'] != 'suspended from practice squad')] # Not including practice squad suspensions\n",
    "    print(\"PST table constructed.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a43fb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_roster_df(con_memory):\n",
    "#   Function name: construct_roster_df\n",
    "#   Description: Create the base of the roster table\n",
    "#   Parameters: con_memory\n",
    "#        con_memory(ducbdb object): used to carry duckdb queries\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The dataframe with all runningbacks in the ../src/rosters folder\n",
    "    \n",
    "    # Allocate all rosters.csv files\n",
    "    save_location = \"../src/rosters\"\n",
    "    directory_path = Path(save_location)\n",
    "    file_paths = [entry for entry in directory_path.iterdir() if entry.is_file()]\n",
    "    file_names = [file.name for file in file_paths]\n",
    "    df = pd.DataFrame()\n",
    "    for i in file_names:\n",
    "        df_temp = pd.read_csv(save_location + \"/\" + i)\n",
    "        df = pd.concat([df, df_temp])\n",
    "\n",
    "    # Create a dataframe from all the rosters.csv files\n",
    "    df = con_memory.execute(\"\"\" SELECT Season, full_name AS name, first_name, last_name, team, position, \n",
    "                                depth_chart_position, pfr_id FROM df \n",
    "                                WHERE position IN ('RB', 'FB', 'HB') \n",
    "                                \"\"\").fetchdf()\n",
    "    df = df[['season', 'name', 'team', 'position']]\n",
    "    \n",
    "    # Make team names consistent with other table\n",
    "    team_nm_fixes = [('CLV', 'CLE'), ('BLT', 'BAL'), ('ARZ', 'ARI'), ('HST', 'HOU'), ('SL', 'STL'), ('LA', 'LAR'), ('SD', 'SDG')]\n",
    "    for wrong_nm, right_nm in team_nm_fixes:\n",
    "        df['team'] = np.where(df.team == wrong_nm, right_nm, df.team)\n",
    "\n",
    "    \n",
    "    df['position'] = 'RB'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a743d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_susp_length_cols(df):\n",
    "#   Function name: find_bye_weeks\n",
    "#   Description: This function is used to add columns that identify the start and end of a suspension\n",
    "#   Parameters: df\n",
    "#        df(pandas dataframe): The base susp_weeks_xref table\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The transformed dataframe with new suspension identifier columns\n",
    "    \n",
    "    x = ''\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f410f45",
   "metadata": {},
   "source": [
    "##### Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5bf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_web_src(url, tbl=0):\n",
    "#   Function name: scrape_web_src\n",
    "#   Description: This function is used to provide a stronger GET request to scrape web data\n",
    "#   Parameters: url, tbl\n",
    "#        url(str): The target URL\n",
    "#        tbl(int): The target table from the scraped web source\n",
    "#   Return values: df\n",
    "#        tables(pandas dataframe): The target table from the URL\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        tables = pd.read_html(response.text)\n",
    "        tables = tables[tbl]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91a055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, save_location, csv_name):\n",
    "#   Function name: save_df\n",
    "#   Description: This function is used to save any dataframe as a csv\n",
    "#   Parameters: df, save_location, csv_name\n",
    "#        df(pandas dataframe): The target dataframe\n",
    "#        save_location(str): Specified location for the csv file to be saved\n",
    "#        csv_name(str): Name of the csv file\n",
    "    \n",
    "    # creates folder if not existence\n",
    "    output_dir = Path(save_location)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    save_loctn = f\"{save_location}/{csv_name}\"\n",
    "    print(f\"Saving {csv_name} at {save_loctn}\")\n",
    "    df.to_csv(save_loctn, index = False)\n",
    "    print(f\"Successfully saved {csv_name}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7922c96f",
   "metadata": {},
   "source": [
    "##### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c9e1a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to construct Wikipedia table from: https://en.wikipedia.org/wiki/List_of_suspensions_in_the_NFL\n",
      "Wikipedia table constructed.\n",
      "Attempting to construct Prosportstransactions.com table from: ../src/nfl_suspensions_by_pst.csv\n",
      "PST table constructed.\n",
      "Saving susp_weeks_xref.csv at ../tables/susp_weeks_xref.csv\n",
      "Successfully saved susp_weeks_xref.csv!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Susp_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>1990-08-30</td>\n",
       "      <td>Indianapolis Colts</td>\n",
       "      <td>Eric Dickerson</td>\n",
       "      <td>6 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>4</td>\n",
       "      <td>1990-10-05</td>\n",
       "      <td>Green Bay Packers</td>\n",
       "      <td>Herman Fontenot</td>\n",
       "      <td>1 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991</td>\n",
       "      <td>9</td>\n",
       "      <td>1991-10-31</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>Tim Worley</td>\n",
       "      <td>6 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991</td>\n",
       "      <td>10</td>\n",
       "      <td>1991-11-08</td>\n",
       "      <td>Indianapolis Colts</td>\n",
       "      <td>Eric Dickerson</td>\n",
       "      <td>4 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992</td>\n",
       "      <td>0</td>\n",
       "      <td>1992-04-30</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>Tim Worley</td>\n",
       "      <td>Entire 1992 season</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>Kansas City Chiefs</td>\n",
       "      <td>De'Anthony Thomas</td>\n",
       "      <td>1 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>Miami Dolphins</td>\n",
       "      <td>Mark Walton</td>\n",
       "      <td>4 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>Tampa Bay Buccaneers</td>\n",
       "      <td>Kenjon Barner</td>\n",
       "      <td>4 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>Kansas City Chiefs</td>\n",
       "      <td>Jerrion Ealy</td>\n",
       "      <td>6 games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>New Orleans Saints</td>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>3 games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season  Week       Date                  Team             Player  \\\n",
       "0     1990     0 1990-08-30    Indianapolis Colts     Eric Dickerson   \n",
       "1     1990     4 1990-10-05     Green Bay Packers    Herman Fontenot   \n",
       "2     1991     9 1991-10-31   Pittsburgh Steelers         Tim Worley   \n",
       "3     1991    10 1991-11-08    Indianapolis Colts     Eric Dickerson   \n",
       "4     1992     0 1992-04-30   Pittsburgh Steelers         Tim Worley   \n",
       "..     ...   ...        ...                   ...                ...   \n",
       "90    2019     0 2019-08-31    Kansas City Chiefs  De'Anthony Thomas   \n",
       "91    2019     9 2019-11-04        Miami Dolphins        Mark Walton   \n",
       "92    2020     4 2020-10-06  Tampa Bay Buccaneers      Kenjon Barner   \n",
       "93    2022     4 2022-10-03    Kansas City Chiefs       Jerrion Ealy   \n",
       "94    2023     0 2023-08-04    New Orleans Saints       Alvin Kamara   \n",
       "\n",
       "              Susp_len  \n",
       "0              6 games  \n",
       "1              1 games  \n",
       "2              6 games  \n",
       "3              4 games  \n",
       "4   Entire 1992 season  \n",
       "..                 ...  \n",
       "90             1 games  \n",
       "91             4 games  \n",
       "92             4 games  \n",
       "93             6 games  \n",
       "94             3 games  \n",
       "\n",
       "[95 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "#   Function name: main\n",
    "#   Description: The entry function of the notebook\n",
    "\n",
    "    con_memory = duckdb.connect(database=':memory:')\n",
    "    wiki = construct_wiki_tbl(con_memory)\n",
    "    suspensions_pst = construct_pst_tbl(con_memory)\n",
    "    \n",
    "    # Union the Wikipedia and PST data to get a unique table with all suspension entries publicly available\n",
    "    df = con_memory.execute(\"\"\"SELECT * FROM \n",
    "                               (SELECT * FROM suspensions_pst \n",
    "                               UNION \n",
    "                               SELECT Season, Week, Date, Team, Player, Susp_len FROM wiki)\n",
    "                               ORDER BY Date, Player\"\"\").fetchdf()\n",
    "    \n",
    "#     df = apply_susp_length_cols(df)\n",
    "    save_df(df, '../tables', 'susp_weeks_xref.csv')\n",
    "    display(df)\n",
    "    con_memory.close()\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFL",
   "language": "python",
   "name": "nfl_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
