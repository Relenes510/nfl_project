{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691cf4d3",
   "metadata": {},
   "source": [
    "### Author: Rodolfo Elenes\n",
    "\n",
    "Date Created: 8/5/2025\n",
    "\n",
    "Change log:\n",
    "8/5/2025 - Initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd04877",
   "metadata": {},
   "source": [
    "# Notebook to do list\n",
    "    1.) Add column that decides if the player had a big injury that season\n",
    "    \n",
    "# Enhancements\n",
    "    1.) Add data validation steps\n",
    "    2.) SQL server implementation over CSV files\n",
    "    3.) Implement using config json files, to make this notebook usable for other positions and store\n",
    "        long information like season mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8619898",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454df37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import traceback\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe54c619",
   "metadata": {},
   "source": [
    "##### Create gamelog functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266acec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_player_gamelog_csv(player_name, pfr_id):\n",
    "#   Function name: create_player_gamelog_csv\n",
    "#   Description: This function is used to generate a dataframe that contains a player's gamelog\n",
    "#   Parameters: player_name, pfr_id\n",
    "#        player_name(str): First and Last name of a player, ex: Saquon Barkley\n",
    "#        pfr_id(str): Pro Football Reference id used in each players URL to retrieve all gamelog information\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The final dataframe that will be exported as a csv file\n",
    "#        status: Tells the parent function this function's run result\n",
    "    \n",
    "    # Get last name initial\n",
    "    lst_nm_initial = player_name[0].capitalize()\n",
    "    \n",
    "    time.sleep(6) # to respect website scraping policies\n",
    "    url = f\"https://www.pro-football-reference.com/players/{lst_nm_initial}/{pfr_id}/gamelog/\"\n",
    "    df = build_career_gmlog_df(url)\n",
    "    \n",
    "    try:\n",
    "        playoffs_df = build_career_gmlog_df(url, playoffs=True)\n",
    "        df = pd.concat([df, playoffs_df])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    status = \"\"\n",
    "    if df.shape[0] <= 8:   # sets minimum game requirement for players to be saved\n",
    "        print(f\"Insufficient gamelog data for {player_name}. Player has {df.shape[0]} games logged.\")\n",
    "        status = \"Insufficient data\"\n",
    "    else:\n",
    "        try:\n",
    "            df = df_rebuild(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Unsupported gamelog schema for {player_name}. Please check: {url}\")\n",
    "            print(\"\\nError:\", e, \"\\n\")\n",
    "            traceback.print_exc()\n",
    "            return df, status\n",
    "        print(f\"Gamelog for {player_name}\")\n",
    "        display(df)\n",
    "        status = \"Save\"\n",
    "        \n",
    "    return df, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdd6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_career_gmlog_df(url, playoffs=False):\n",
    "#   Function name: build_career_gmlog_df\n",
    "#   Description: This function is used to scrape the raw dataframe of the player's gamelog from pfr's website \n",
    "#   Parameters: url, playoffs\n",
    "#        url(str): The URL that points to a player's gamelog\n",
    "#        playoffs(boolean): Tells the function to extract the regular season or playoffs table\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The raw dataframe that will be transformed into the final dataframe\n",
    "    \n",
    "    if playoffs == True:\n",
    "        df = pd.read_html(url, header=[0, 1])[1]\n",
    "    else:\n",
    "        df = pd.read_html(url, header=[0, 1])[0]\n",
    "        \n",
    "    # Fill top-level header missing values forward\n",
    "    cols = pd.DataFrame(df.columns.tolist())\n",
    "    cols.iloc[:, 0] = cols.iloc[:, 0].replace(\"Unnamed:.*\", pd.NA, regex=True).fillna(method='ffill')\n",
    "    # Rebuild MultiIndex\n",
    "    df.columns = pd.MultiIndex.from_frame(cols)\n",
    "    df = df[['NaN', 'Rushing', 'Receiving', 'Snap Counts']]\n",
    "\n",
    "    # Then flatten as before\n",
    "    df.columns = [\n",
    "        f\"{a}_{b}\".strip('_') if b else a \n",
    "        for a, b in df.columns\n",
    "    ]\n",
    "\n",
    "    if playoffs == True:\n",
    "        df['Season_type'] = \"POST\"\n",
    "    else:\n",
    "        df['Season_type'] = \"REG\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6cd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_rebuild(df):\n",
    "#   Function name: df_rebuild\n",
    "#   Description: This function is used to take the raw dataframe and apply all necessary transformations\n",
    "#   Parameters: df\n",
    "#        df(pandas dataframe): The raw input dataframe\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The final dataframe that will be saved as a csv file\n",
    "\n",
    "    # Remove nan_ from Date and GS, rename Gcar col\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        if \"nan\" in col:\n",
    "            if col == 'nan_Gcar':  # Exclusively rename Gcar to CarGm\n",
    "                col = 'CarGm'\n",
    "            new_cols.append(col.replace(\"nan_\", \"\"))\n",
    "        else:\n",
    "            new_cols.append(col)\n",
    "    df.columns = new_cols\n",
    "\n",
    "    # Drop unneccesary rows\n",
    "    process_columns = ['CarGm', 'Date', 'GS', 'Season_type', 'Week', 'Team', 'Rushing_Att', 'Rushing_Yds', 'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec', 'Receiving_Yds', 'Receiving_TD', 'Snap Counts_OffSnp', 'Snap Counts_Off%', 'Snap Counts_STSnp','Snap Counts_ST%']\n",
    "    df = df[process_columns]\n",
    "    \n",
    "    # filter out rows that do not contain games (i.e. header rows, summary rows, etc.)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).reset_index(drop = True)\n",
    "    \n",
    "    # Create Season column\n",
    "    min_year = (df['Date'].min().year) - 1  # subtracting for players who debutted in next calendar year\n",
    "    max_year = df['Date'].max().year\n",
    "    df['Season'] = ''\n",
    "    for i in range(max_year, min_year - 1, -1):\n",
    "        start_date = f\"{i}-08-01\"\n",
    "        end_date = f\"{i + 1}-03-01\"\n",
    "        date_filter = (df['Date'] > start_date) & (df['Date'] <= end_date)\n",
    "        df[\"Season\"] = np.where(date_filter, i, df[\"Season\"])\n",
    "\n",
    "    # Final column rename\n",
    "    edit_df_cols = df.columns.tolist()\n",
    "    final_columns = ['CarGm', 'Date', 'GS', 'Season_type', 'Week', 'Team', 'RushAtt', 'RushYds', 'RushTD', 'Tgt', 'Rec', 'RecYds', 'RecTD', 'OffSnp', 'OffSnp%', 'STSnp', 'STSnp%', 'Season']\n",
    "    for i in range(df.shape[1]):\n",
    "        edit_df_cols[i] = final_columns[i]\n",
    "    df.columns = edit_df_cols\n",
    "    \n",
    "    df['GS'] = np.where(df['GS'] == '*', 1, 0)  # make Game Started column binary\n",
    "    df = apply_schema(df)\n",
    "        \n",
    "    # Final order\n",
    "    column_order = ['CarGm', 'Date', 'Season', 'Season_type', 'Week', 'Team', 'GS', 'RushAtt', 'RushYds', 'RushTD', 'Tgt', 'Rec', 'RecYds', 'RecTD', 'OffSnp', 'OffSnp%', 'STSnp', 'STSnp%']\n",
    "    df = df[column_order].sort_values(\"Date\").reset_index(drop=True)\n",
    "    df['CarGm'] = range(1, len(df) + 1) # Numerize the Career Games based off the Dates\n",
    "    df = add_DNP_rows(df)\n",
    "    df = find_bye_weeks(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08166fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_schema(df):\n",
    "#   Function name: apply_schema\n",
    "#   Description: This function is used to apply the correct dataframe schema\n",
    "#   Parameters: df\n",
    "#        input_df(pandas dataframe): The input dataframe\n",
    "#   Return values: df, status\n",
    "#        df(pandas dataframe): The transformed dataframe with correct datatypes schema\n",
    "    \n",
    "    # apply proper schema\n",
    "    int_cols = ['CarGm', 'Season', 'Week', 'GS', 'RushAtt', 'RushYds', 'RushTD', 'Tgt', 'Rec', 'RecYds', 'RecTD', 'OffSnp', 'STSnp']\n",
    "    for col in int_cols:\n",
    "        df[col] = df[col].astype(float).astype(int)\n",
    "    \n",
    "    float_cols = ['OffSnp%', 'STSnp%']\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype(float)\n",
    "        \n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea74baf",
   "metadata": {},
   "source": [
    "##### DNP rows manipulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24c7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_DNP_rows(input_df):\n",
    "#   Function name: add_DNP_rows\n",
    "#   Description: This function is used to add missing DNP rows to the dataframe\n",
    "#   Parameters: input_df\n",
    "#        input_df(pandas dataframe): The input dataframe\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The transformed dataframe with DNP rows\n",
    "    \n",
    "    career_seasons = input_df['Season'].unique().tolist() # get the seasons in a list\n",
    "\n",
    "    df_gamelog = input_df[(input_df['Season_type'] == 'REG')] # exclude playoffs rows\n",
    "    df_playoffs = input_df[(input_df['Season_type'] == 'POST')] # store playoffs rows\n",
    "    final_columns = input_df.columns\n",
    "    df = pd.DataFrame(columns = final_columns)\n",
    "\n",
    "    # split df_gamelog by seasons\n",
    "    for season in career_seasons:\n",
    "        df_season = df_gamelog[(df_gamelog['Season']) == season]\n",
    "        if season >= 2021:\n",
    "            week_games = list(range(1, 19))\n",
    "        else:\n",
    "            week_games = list(range(1, 18))\n",
    "\n",
    "        df_DNP = pd.DataFrame(columns = final_columns)\n",
    "        games_played = df_season['Week'].tolist()  # get weeks value from season\n",
    "        weeks_missed = list(set(week_games) - set(games_played))  # get games missed\n",
    "\n",
    "        #add DNP rows\n",
    "        for week in weeks_missed:        \n",
    "            df_DNP.loc[-1] = {'Week': week, 'Season_type': 'DNP', 'Season': season}  # Add DNP row\n",
    "            df_DNP = df_DNP.reset_index(drop=True)\n",
    "\n",
    "        df_season = pd.concat([df_season, df_DNP]).sort_values('Week').reset_index(drop=True)\n",
    "        df_season['Team'] = df_season['Team'].ffill()  # fills DNP week with correct team\n",
    "        if df_season['Team'].isna().any(): # in case forward fill doesnt work due to a player beginning the season injured\n",
    "            df_season['Team'] = df_season['Team'].bfill()\n",
    "        df_season = df_season.fillna(0)\n",
    "        df = pd.concat([df, df_season])\n",
    "\n",
    "    df = pd.concat([df, df_playoffs])\n",
    "    df = df.sort_values(by = ['Season', 'Week']).reset_index(drop=True)\n",
    "    df = apply_schema(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d57b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bye_weeks(df):\n",
    "#   Function name: find_bye_weeks\n",
    "#   Description: This function is used to correctly identify the bye weeks on DNP rows\n",
    "#   Parameters: df\n",
    "#        df(pandas dataframe): The input dataframe\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The transformed dataframe with BYE week rows\n",
    "\n",
    "    df_fltrd = df[(df[\"Season_type\"] == 'DNP')]\n",
    "    teams_played_for = df_fltrd['Team'].unique().tolist()\n",
    "    years_played_for = df_fltrd['Season'].unique().tolist()\n",
    "\n",
    "    df_teams = pd.read_csv(\"../tables/team_info_xref.csv\")\n",
    "    df_ABV = df_teams.dropna(subset=['ABV2']).reset_index(drop=True)\n",
    "\n",
    "    # Flatten team_info_xref to have extra ABVs in its own rows\n",
    "    row_loc = -1 # the pointer for the last row of the dataframe\n",
    "    for row in range(df_ABV.shape[0]):\n",
    "        team_entry = df_ABV.loc[row]\n",
    "        team_name = team_entry.loc['Team']\n",
    "        ABV2 = team_entry.loc['ABV2']\n",
    "        ABV3 = team_entry.loc['ABV3']\n",
    "        df_teams.loc[row_loc] = {'Team': team_name, 'ABV': ABV2}  # Add row with secondary abbreviations       \n",
    "        row_loc = row_loc - 1\n",
    "        if str(ABV3) != 'nan':\n",
    "            df_teams.loc[row_loc] = {'Team': team_name, 'ABV': ABV3}  # Add row with third abbreviations \n",
    "            row_loc = row_loc - 1\n",
    "    df_teams = df_teams[['Team', 'ABV']].sort_values('Team').reset_index(drop=True)\n",
    "\n",
    "    # Get all the bye weeks relevant to the player\n",
    "    df_bye = pd.read_csv(\"../tables/bye_weeks_xref/bye_weeks_xref.csv\")\n",
    "    df_bye = pd.merge(df_bye, df_teams, on='Team', how='inner')\n",
    "    drop_condition = df_bye[(df_bye['Team'] == 'Tennessee Titans') & (df_bye['ABV'] == 'HOU') & \n",
    "                            (df_bye['Season'] >= 1997)].index\n",
    "    df_bye = df_bye.drop(drop_condition) # Remove Titans HOU ABV (meant for the oilers) where the season >= 1997\n",
    "    df_bye = df_bye[df_bye.ABV.isin(teams_played_for)].reset_index(drop=True)\n",
    "    df_bye = df_bye[df_bye.Season.isin(years_played_for)].reset_index(drop=True)\n",
    "    df_bye = df_bye[['ABV', 'Season', 'Bye Week']]\n",
    "    \n",
    "    # Match the correct bye week to the players log on DNP rows\n",
    "    merged_df = pd.merge(df_fltrd, df_bye, left_on=['Team', 'Season'], right_on=['ABV', 'Season'], how='inner')\n",
    "    merged_df = merged_df[(merged_df[\"Week\"] == merged_df[\"Bye Week\"])]\n",
    "    merged_df['Season_type'] = \"BYE\"\n",
    "    merged_df = merged_df[df.columns].reset_index(drop=True)\n",
    "\n",
    "    # Apply BYE week rows to the final df\n",
    "    for row in range(merged_df.shape[0]):\n",
    "        week_entry = merged_df.loc[row]\n",
    "        season = week_entry.loc['Season']\n",
    "        week = week_entry.loc['Week']\n",
    "        index_row = df[(df['Season'] == season) & (df['Week'] == week)].index[0]\n",
    "        df.loc[index_row] = week_entry\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963a3c2",
   "metadata": {},
   "source": [
    "##### Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100c8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_player_tbl(df, player_name):\n",
    "#   Function name: save_player_tbl\n",
    "#   Description: This function is used to save the final dataframe as a csv file\n",
    "#   Parameters: df, player_name\n",
    "#        df(pandas dataframe): The final dataframe\n",
    "#        player_name(str): The first and last name of the player\n",
    "    \n",
    "    # creates players folder if not existence\n",
    "    output_dir = Path('../tables/players_gamelog')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    save_loctn = f\"../tables/players_gamelog/{player_name}_gamelog.csv\"\n",
    "    print(f\"Saving gamelog data for {player_name} to {save_loctn}.\")\n",
    "    df.to_csv(save_loctn, index = False)\n",
    "    print(\"Gamelog data saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8b48a",
   "metadata": {},
   "source": [
    "###### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c085f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All players that will have gamelog data scraped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team</th>\n",
       "      <th>position</th>\n",
       "      <th>full_name</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>years_exp</th>\n",
       "      <th>pfr_id</th>\n",
       "      <th>gm_log_rtrvd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [season, team, position, full_name, height, weight, age, years_exp, pfr_id, gm_log_rtrvd]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed acquiring gamelog for 0 players.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "#   Function name: main\n",
    "#   Description: The entry function of the notebook\n",
    "\n",
    "    print(\"All players that will have gamelog data scraped.\")\n",
    "    players_xref_path = \"../tables/players_xref.csv\"\n",
    "    player_db = pd.read_csv(players_xref_path)\n",
    "    fltrd_player_db = player_db[player_db['gm_log_rtrvd'] == 0].reset_index(drop = True)\n",
    "    player_count = 1\n",
    "    display(fltrd_player_db)\n",
    "    \n",
    "    for row in range(player_db.shape[0]):\n",
    "        player_entry = player_db.loc[row]\n",
    "        player_name = player_entry.loc['full_name']\n",
    "        pfr_id = player_entry.loc['pfr_id']\n",
    "        gm_log_rtrvd = player_entry.loc['gm_log_rtrvd']\n",
    "        \n",
    "        if gm_log_rtrvd == 0:\n",
    "            print(f\"Player ({player_count}/{fltrd_player_db.shape[0]}): {player_name}\")\n",
    "            df, status = create_player_gamelog_csv(player_name, pfr_id)\n",
    "            \n",
    "            if status == \"Save\":\n",
    "                save_player_tbl(df, player_name)\n",
    "                player_db.loc[row, 'gm_log_rtrvd'] = 1 # Successful save\n",
    "            elif status == \"Insufficient data\":\n",
    "                player_db.loc[row, 'gm_log_rtrvd'] = 2 # Insufficient data\n",
    "            else:\n",
    "                player_db.loc[row, 'gm_log_rtrvd'] = 3 # Failed save (lets me know to debug)\n",
    "            player_db.to_csv(players_xref_path, index = False)\n",
    "            \n",
    "            print(f\"Updated gm_log_rtrvd entry in players_ref.csv for {player_name}\")\n",
    "            player_count = player_count + 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    print(f\"Completed acquiring gamelog for {fltrd_player_db.shape[0]} players.\")\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurobi",
   "language": "python",
   "name": "gurobi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
