{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099d2190",
   "metadata": {},
   "source": [
    "### Author: Rodolfo Elenes\n",
    "\n",
    "Date Created: 9/24/2025\n",
    "\n",
    "Purpose: To pull injury information from available sources and store the injury logs into one table\n",
    "\n",
    "Change log:\n",
    "- 9/24/2025 - Initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ef051",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./common_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4e6fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def collect_inj_nfl_web(con):\n",
    "#   Function name: collect_inj_nflverse\n",
    "#   Description: Collect injuries from NFL.com weekly injury reports\n",
    "#   Parameters: con\n",
    "#        con(duckdb database): Used to connect to duckdb session\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The dataframe with weekly NFL.com injuries\n",
    "\n",
    "    start_szn = 2001 # Expect to see injuries report come up around 2002 week 1\n",
    "    df_dates = pd.read_csv(\"../tables/nfl_dates_xref.csv\")\n",
    "\n",
    "    seasons = list(range(start_szn, 2025))\n",
    "    df = pd.DataFrame()\n",
    "    for year in seasons:\n",
    "        df_temp = con.execute(f\"\"\"SELECT * FROM df_dates WHERE Season = '{year}' AND Season_type = 'REG'\"\"\").fetchdf()\n",
    "        display(df_temp)\n",
    "        weeks = df_temp.Week.unique().tolist()\n",
    "        for week in weeks:\n",
    "            print(f\"Collecting Week {week} from the {year} Season.\")\n",
    "            url = f\"https://www.nfl.com/injuries/league/{year}/reg{week}\"\n",
    "            time.sleep(4)\n",
    "            try:\n",
    "                result = pd.read_html(url)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            tm_count = 0\n",
    "            for i in range(0, 40):\n",
    "                try:\n",
    "                    df_temp = result[i]\n",
    "                    df_temp['Season'] = year\n",
    "                    df_temp['Week'] = week\n",
    "                    df_temp = df_temp[['Season', 'Week', 'Player', 'Position', 'Injuries', 'Practice Status', 'Game Status']]\n",
    "                    tm_count += 1\n",
    "                    df = pd.concat([df, df_temp])\n",
    "                except:\n",
    "                    pass\n",
    "            print(f\"{tm_count} injury reports collected.\")\n",
    "    df.to_csv(\"../src/nfl_web_injuries.csv\", index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7582dd9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def collect_inj_nflverse(con):\n",
    "#   Function name: collect_inj_nflverse\n",
    "#   Description: Collect injuries from the downloaded NFLVerse dataset\n",
    "#   Parameters: con\n",
    "#        con(duckdb database): Used to connect to duckdb session\n",
    "#   Return values: df\n",
    "#        df(pandas dataframe): The dataframe with weekly NFLVerse injuries\n",
    "\n",
    "    # Allocate all rosters.csv files\n",
    "    save_location = \"../src/injuries\"\n",
    "    directory_path = Path(save_location)\n",
    "    file_paths = [entry for entry in directory_path.iterdir() if entry.is_file()]\n",
    "    file_names = [file.name for file in file_paths]\n",
    "    df = pd.DataFrame()\n",
    "    for i in file_names:\n",
    "        df_temp = pd.read_csv(save_location + \"/\" + i)\n",
    "        df = pd.concat([df, df_temp])\n",
    "\n",
    "    df = df[(df.game_type == 'REG') & (df.position.isin(['FB', 'RB'])) & ~(df.report_status.isnull())]\n",
    "\n",
    "    # Make team names consistent with team_info_xref table\n",
    "    team_nm_fixes = [('GB', 'GNB'), ('KC', 'KAN'), ('LA', 'LAR'), ('LV', 'LVR'), ('NE', 'NWE'), ('NO', 'NOR'),\n",
    "                     ('SD', 'SDG'), ('SF', 'SFO'), ('TB', 'TAM')]\n",
    "    for wrong_nm, right_nm in team_nm_fixes:\n",
    "        df['team'] = np.where(df.team == wrong_nm, right_nm, df.team)\n",
    "\n",
    "    df['Injuries'] = df[['report_primary_injury', 'report_secondary_injury']] \\\n",
    "        .fillna('') \\\n",
    "        .apply(lambda x: ', '.join([i for i in x if i != '']), axis=1)\n",
    "\n",
    "\n",
    "    df['Injuries'] = np.where(\n",
    "        df['Injuries'] == '',  # element-wise access to second part\n",
    "        np.nan,        # keep first part if second is empty\n",
    "        df['Injuries']                                  # otherwise keep original\n",
    "    )\n",
    "\n",
    "    df = con.execute(\"\"\"SELECT season as Season, week as Week, full_name as Player, team as Team, position as Position, Injuries, report_status FROM df\"\"\").fetchdf()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9cdd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "#   Function name: main\n",
    "#   Description: The entry function of the notebook, also does final transformations for final table\n",
    "\n",
    "    con = duckdb.connect(database=':memory:')\n",
    "    df = collect_inj_nfl_web(con)    \n",
    "#     df = pd.read_csv(\"../src/nfl_web_injuries.csv\") # To perform quicker testing\n",
    "\n",
    "    display(df)\n",
    "    df = df[~(df['Game Status'].isnull()) & (df.Position.isin(['RB', 'FB', 'HB']))]\n",
    "    df = con.execute(\"\"\"SELECT Season, Week, Player, Position, Injuries, \"Game Status\" as report_status FROM df\"\"\").fetchdf()\n",
    "    df_roster = construct_df_roster(con)\n",
    "    df = con.execute(\"\"\"SELECT df.Season, df.Week, df.Player, df_roster.ABV as Team, df.Position, df.Injuries, df.report_status FROM df \n",
    "                         JOIN df_roster ON df.Season = df_roster.Season AND df.Player = df_roster.Player\"\"\").fetchdf()\n",
    "\n",
    "    df2 = collect_inj_nflverse(con)\n",
    "\n",
    "    df3 = con.execute(\"\"\"SELECT * EXCLUDE (report_status), report_status AS \"Game Status\" FROM(SELECT * FROM df UNION SELECT * FROM df2)\"\"\").fetchdf()\n",
    "    display(df3)\n",
    "    df3.to_csv(\"../tables/injuries_xref.csv\", index=False)\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFL",
   "language": "python",
   "name": "nfl_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
